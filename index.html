<!DOCTYPE html>
<html lang="zh-CN">
<head>
  <meta charset="UTF-8">
  <title>ÈπÖÂî±Ê≠åÊ£ÄÊµã</title>
  <style>
    body {
      margin: 0;
      background: #000;
      color: #fff;
      text-align: center;
      font-family: 'Arial', sans-serif;
    }
    video {
      margin-top: 20px;
      width: 320px;
      height: 240px;
      border: 2px solid #fff;
      border-radius: 10px;
    }
    #status {
      font-size: 36px;
      margin-top: 20px;
    }
    #goose {
      margin-top: 20px;
      display: none;
      width: 200px;
      height: auto;
    }
  </style>
  <script src="https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@latest/vision_bundle.mjs" type="module"></script>
</head>
<body>
  <h1>ü™ø Èó≠ÁúºËÆ©ÈπÖÂî±Ê≠å üéµ</h1>
  <video id="video" autoplay playsinline></video>
  <div id="status">Âä†ËΩΩ‰∏≠...</div>
  <img id="goose" src="https://upload.wikimedia.org/wikipedia/commons/7/7b/Goose_icon.png" alt="Âî±Ê≠åÁöÑÈπÖ">
  <audio id="gooseSound" src="https://github.com/DianaJiang233/GooseSing/blob/main/do3.wav" loop></audio>

  <script type="module">
    import { FilesetResolver, FaceLandmarker } from "https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@latest/vision_bundle.mjs";

    const video = document.getElementById('video');
    const statusText = document.getElementById('status');
    const gooseImg = document.getElementById('goose');
    const gooseSound = document.getElementById('gooseSound');

    let isGooseSinging = false;

    async function init() {
      const vision = await FilesetResolver.forVisionTasks(
        "https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@latest/wasm"
      );

      const faceLandmarker = await FaceLandmarker.createFromOptions(vision, {
        baseOptions: {
          modelAssetPath: "https://storage.googleapis.com/mediapipe-assets/face_landmarker.task",
          delegate: "GPU",
        },
        outputFaceBlendshapes: false,
        outputFacialTransformationMatrixes: false,
        runningMode: "VIDEO",
        numFaces: 1,
      });

      const stream = await navigator.mediaDevices.getUserMedia({ video: true });
      video.srcObject = stream;

      async function detect() {
        if (video.readyState < 2) {
          requestAnimationFrame(detect);
          return;
        }

        const nowInMs = Date.now();
        const results = faceLandmarker.detectForVideo(video, nowInMs);

        if (results.faceLandmarks.length > 0) {
          const landmarks = results.faceLandmarks[0];

          const leftEyeOpenScore = getEyeOpenScore(landmarks, 159, 145);
          const rightEyeOpenScore = getEyeOpenScore(landmarks, 386, 374);

          const eyeOpen = (leftEyeOpenScore > 0.02) && (rightEyeOpenScore > 0.02);

          if (eyeOpen) {
            statusText.textContent = "ËØ∑Èó≠Áúº üí§";
            gooseImg.style.display = "none";
            if (isGooseSinging) {
              gooseSound.pause();
              gooseSound.currentTime = 0;
              isGooseSinging = false;
            }
          } else {
            statusText.textContent = "ÈπÖÂú®Âî±Ê≠å üéµ";
            gooseImg.style.display = "block";
            if (!isGooseSinging) {
              gooseSound.play().catch(e => {
                console.log("Êí≠ÊîæÂá∫ÈîôÔºåÁÇπ‰∏Ä‰∏ãÈ°µÈù¢ÔºÅ", e);
              });
              isGooseSinging = true;
            }
          }
        } else {
          statusText.textContent = "Êú™Ê£ÄÊµãÂà∞‰∫∫ËÑ∏";
          gooseImg.style.display = "none";
          if (isGooseSinging) {
            gooseSound.pause();
            gooseSound.currentTime = 0;
            isGooseSinging = false;
          }
        }

        requestAnimationFrame(detect);
      }

      detect();
    }

    function getEyeOpenScore(landmarks, topIdx, bottomIdx) {
      const top = landmarks[topIdx];
      const bottom = landmarks[bottomIdx];
      const dy = bottom.y - top.y;
      return dy;
    }

    init();
  </script>
</body>
</html>
