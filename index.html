<!DOCTYPE html>
<html lang="zh">
<head>
  <meta charset="UTF-8">
  <title>é—­ä¸Šçœ¼ç›çš„å°é¹… - ç¨³å®šä¿®æ­£å®Œç¾ç‰ˆ</title>
  <style>
    body {
      background-color: black;
      color: white;
      text-align: center;
      font-family: sans-serif;
      margin-top: 50px;
    }
    #goose {
      font-size: 100px;
      margin-top: 20px;
    }
    #message {
      margin-top: 20px;
      font-size: 24px;
    }
    #startButton {
      margin-top: 30px;
      padding: 10px 20px;
      font-size: 20px;
      border: none;
      border-radius: 8px;
      background-color: white;
      color: black;
      cursor: pointer;
    }
    video {
      display: none;
    }
  </style>
</head>
<body>

<h1>å°é¹…è¯´ï¼šé—­ä¸Šçœ¼ç›æ‰èƒ½å¬éŸ³ä¹å“¦ï½ğŸª¿</h1>

<div id="goose">ğŸª¿</div>
<div id="message">è¯·ç‚¹å‡»ä¸‹é¢æŒ‰é’®å¼€å§‹</div>
<button id="startButton">å¼€å§‹</button>

<video id="video" autoplay playsinline muted></video>

<!-- æ­£ç¡®å¼•ç”¨ï¼Œä¸éœ€è¦è‡ªå·±å¼•tfjs -->
<script type="module">
import * as faceLandmarksDetection from 'https://cdn.jsdelivr.net/npm/@tensorflow-models/face-landmarks-detection/dist/face-landmarks-detection.esm.js';
import { Tone } from 'https://cdn.jsdelivr.net/npm/tone@14.7.77/build/Tone.js';

const goose = document.getElementById('goose');
const message = document.getElementById('message');
const video = document.getElementById('video');
const startButton = document.getElementById('startButton');

let model;
let playingMusic = false;

// éŸ³ä¹åˆæˆå™¨
const synth = new Tone.Synth().toDestination();
function playMusic() {
  synth.triggerAttackRelease('C4', '8n');
  synth.triggerAttackRelease('E4', '8n', '+0.5');
  synth.triggerAttackRelease('G4', '8n', '+1');
}

// æ£€æµ‹çœ¼ç›æ˜¯å¦é—­ä¸Š
function isEyesClosed(landmarks) {
  const leftTop = landmarks[159];
  const leftBottom = landmarks[145];
  const distance = Math.hypot(leftTop.x - leftBottom.x, leftTop.y - leftBottom.y);
  return distance < 0.005;
}

// ç‚¹å‡»å¼€å§‹
startButton.addEventListener('click', async () => {
  startButton.style.display = 'none';
  message.innerText = "å°é¹…è¯´ï¼šå¿«é—­ä¸Šçœ¼ç›ï½";

  const stream = await navigator.mediaDevices.getUserMedia({ video: true });
  video.srcObject = stream;
  await video.play();

  model = await faceLandmarksDetection.load(faceLandmarksDetection.SupportedPackages.mediapipeFacemesh);

  detectLoop();
});

// å¾ªç¯æ£€æµ‹
async function detectLoop() {
  if (!model) return;

  const predictions = await model.estimateFaces({input: video, returnTensors: false});
  
  if (predictions.length > 0) {
    const keypoints = predictions[0].scaledMesh;

    if (isEyesClosed(keypoints)) {
      message.innerText = "é¹…åœ¨æ¼”å¥éŸ³ä¹ğŸµ";
      goose.innerText = "ğŸ¶ğŸª¿ğŸ¶";
      if (!playingMusic) {
        playingMusic = true;
        Tone.start();
        playMusic();
      }
    } else {
      message.innerText = "å¿«é—­ä¸Šçœ¼ç›ï¼";
      goose.innerText = "ğŸ˜ ğŸª¿";
      playingMusic = false;
    }
  } else {
    message.innerText = "å°é¹…æ‰¾ä¸åˆ°ä½ çš„è„¸å‘¢ï½";
    goose.innerText = "â“ğŸª¿";
  }

  requestAnimationFrame(detectLoop);
}
</script>

</body>
</html>
