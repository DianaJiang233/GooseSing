<!DOCTYPE html>
<html lang="zh-CN">
<head>
  <meta charset="UTF-8">
  <title>鹅唱歌检测</title>
  <style>
    body {
      margin: 0;
      background: #000;
      color: #fff;
      text-align: center;
      font-family: 'Arial', sans-serif;
    }
    video {
      margin-top: 20px;
      width: 320px;
      height: 240px;
      border: 2px solid #fff;
      border-radius: 10px;
    }
    #status {
      font-size: 36px;
      margin-top: 20px;
    }
    #goose {
      margin-top: 20px;
      display: none;
      width: 200px;
      height: auto;
    }
  </style>
  <script src="https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@latest/vision_bundle.mjs" type="module"></script>
</head>
<body>
  <h1>🪿 闭眼让鹅唱歌 🎵</h1>
  <video id="video" autoplay playsinline></video>
  <div id="status">加载中...</div>
  <img id="goose" src="https://upload.wikimedia.org/wikipedia/commons/7/7b/Goose_icon.png" alt="唱歌的鹅">
  <audio id="gooseSound" src="https://cdn.pixabay.com/audio/2022/03/15/audio_f4a88b6f37.mp3" loop></audio>

  <script type="module">
    import { FilesetResolver, FaceLandmarker } from "https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@latest/vision_bundle.mjs";

    const video = document.getElementById('video');
    const statusText = document.getElementById('status');
    const gooseImg = document.getElementById('goose');
    const gooseSound = document.getElementById('gooseSound');

    let isGooseSinging = false;

    async function init() {
      const vision = await FilesetResolver.forVisionTasks(
        "https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@latest/wasm"
      );

      const faceLandmarker = await FaceLandmarker.createFromOptions(vision, {
        baseOptions: {
          modelAssetPath: "https://storage.googleapis.com/mediapipe-assets/face_landmarker.task",
          delegate: "GPU",
        },
        outputFaceBlendshapes: false,
        outputFacialTransformationMatrixes: false,
        runningMode: "VIDEO",
        numFaces: 1,
      });

      const stream = await navigator.mediaDevices.getUserMedia({ video: true });
      video.srcObject = stream;

      async function detect() {
        if (video.readyState < 2) {
          requestAnimationFrame(detect);
          return;
        }

        const nowInMs = Date.now();
        const results = faceLandmarker.detectForVideo(video, nowInMs);

        if (results.faceLandmarks.length > 0) {
          const landmarks = results.faceLandmarks[0];

          const leftEyeOpenScore = getEyeOpenScore(landmarks, 159, 145);
          const rightEyeOpenScore = getEyeOpenScore(landmarks, 386, 374);

          const eyeOpen = (leftEyeOpenScore > 0.02) && (rightEyeOpenScore > 0.02);

          if (eyeOpen) {
            // 睁眼状态
            statusText.textContent = "请闭眼 💤";
            gooseImg.style.display = "none";
            if (isGooseSinging) {
              gooseSound.pause();
              gooseSound.currentTime = 0;
              isGooseSinging = false;
            }
          } else {
            // 闭眼状态
            statusText.textContent = "鹅在唱歌 🎵";
            gooseImg.style.display = "block";
            if (!isGooseSinging) {
              gooseSound.play().catch(e => {
                console.log("播放出错，可能是浏览器安全限制，需要用户先点一下页面", e);
              });
              isGooseSinging = true;
            }
          }
        } else {
          statusText.textContent = "未检测到人脸";
          gooseImg.style.display = "none";
          if (isGooseSinging) {
            gooseSound.pause();
            gooseSound.currentTime = 0;
            isGooseSinging = false;
          }
        }

        requestAnimationFrame(detect);
      }

      detect();
    }

    function getEyeOpenScore(landmarks, topIdx, bottomIdx) {
      const top = landmarks[topIdx];
      const bottom = landmarks[bottomIdx];
      const dy = bottom.y - top.y;
      return dy;
    }

    init();
  </script>
</body>
</html>
